{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-03-17T03:23:23.388071Z",
     "start_time": "2020-03-17T03:23:12.402438Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tools\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Sampling & Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split, KFold \n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, fbeta_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Load train and test sets\n",
    "# df            = pd.read_pickle('../data/df.pkl')\n",
    "X_train_under = pd.read_pickle('../data/03_X_train_under.pkl')\n",
    "X_test        = pd.read_pickle('../data/03_X_test.pkl')\n",
    "y_train_under = pd.read_pickle('../data/03_y_train_under.pkl')\n",
    "y_test        = pd.read_pickle('../data/03_y_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Objective: Maximize F1 & ROC AUC Score as both recall and precision are equally important and the classes are imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Create list to store model performance\n",
    "model_performance = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "User RandomizedSearchCV instead:\n",
    "https://blog.usejournal.com/a-comparison-of-grid-search-and-randomized-search-using-scikit-learn-29823179bc85\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y actual\t: Counter({0: 83653, 1: 22301})\n",
      "y predicted\t: Counter({0: 105954})\n",
      "\n",
      "Confusion Matrix\n",
      "[[83653     0]\n",
      " [22301     0]]\n"
     ]
    }
   ],
   "source": [
    "#Dummy Classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier(strategy= 'most_frequent').fit(X_train_under, y_train_under)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#Distribution of y test\n",
    "print('y actual\\t:', Counter(y_test))\n",
    "\n",
    "#Distribution of y predicted\n",
    "print('y predicted\\t:', Counter(y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\nConfusion Matrix\\n' + str(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# base_models = []\n",
    "\n",
    "# # Instantiate the models\n",
    "# base_models.append(('LogisticRegression', LogisticRegression(solver='liblinear')))\n",
    "# base_models.append(('KNeighbors', KNeighborsClassifier()))\n",
    "# base_models.append(('RandomForest', RandomForestClassifier(n_estimators=10)))\n",
    "# base_models.append(('XGBoost', XGBClassifier()))\n",
    "\n",
    "# cv_results = []\n",
    "# names = []\n",
    "\n",
    "# # Cross Validate - 5 fold\n",
    "# for name, model in base_models:\n",
    "#     names.append(name)\n",
    "#     cv_results.append(np.round_(cross_val_score(model, X_train_under, y_train_under, \n",
    "#                                                 cv=5, scoring='roc_auc', n_jobs=-1), 3))\n",
    "\n",
    "# for i in range(len(names)):\n",
    "#     print(names[i], round(cv_results[i].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.743\n",
      "Params: {'und__random_state': 2020, 'lgr__solver': 'saga', 'lgr__penalty': 'l2', 'lgr__C': 10}\n",
      "\n",
      "Train 0.744\tTest 0.743\tParams: {'und__random_state': 2020, 'lgr__solver': 'liblinear', 'lgr__penalty': 'l2', 'lgr__C': 10}\n",
      "Train 0.741\tTest 0.741\tParams: {'und__random_state': 2020, 'lgr__solver': 'liblinear', 'lgr__penalty': 'l2', 'lgr__C': 0.1}\n",
      "Train 0.743\tTest 0.742\tParams: {'und__random_state': 2020, 'lgr__solver': 'liblinear', 'lgr__penalty': 'l1', 'lgr__C': 0.1}\n",
      "Train 0.744\tTest 0.743\tParams: {'und__random_state': 2020, 'lgr__solver': 'saga', 'lgr__penalty': 'l2', 'lgr__C': 100}\n",
      "Train 0.744\tTest 0.743\tParams: {'und__random_state': 2020, 'lgr__solver': 'liblinear', 'lgr__penalty': 'l2', 'lgr__C': 1000}\n",
      "Train 0.744\tTest 0.743\tParams: {'und__random_state': 2020, 'lgr__solver': 'liblinear', 'lgr__penalty': 'l1', 'lgr__C': 10}\n",
      "Train 0.744\tTest 0.743\tParams: {'und__random_state': 2020, 'lgr__solver': 'saga', 'lgr__penalty': 'l2', 'lgr__C': 10}\n",
      "Train 0.744\tTest 0.743\tParams: {'und__random_state': 2020, 'lgr__solver': 'liblinear', 'lgr__penalty': 'l1', 'lgr__C': 100}\n",
      "Train 0.73\tTest 0.73\tParams: {'und__random_state': 2020, 'lgr__solver': 'saga', 'lgr__penalty': 'l2', 'lgr__C': 0.01}\n",
      "Train 0.698\tTest 0.697\tParams: {'und__random_state': 2020, 'lgr__solver': 'liblinear', 'lgr__penalty': 'l1', 'lgr__C': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Grid searching key hyperparameters for logistic regression\n",
    "\n",
    "# Instantiate model and sampler\n",
    "lg_model = LogisticRegression()\n",
    "under = RandomUnderSampler(random_state=2020)\n",
    "\n",
    "# Construct pipeline\n",
    "steps = [('und', under), ('lgr', lg_model)]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Define parameter grid values to be searched\n",
    "param_grid = {\n",
    "    'und__random_state': [2020],\n",
    "    'lgr__solver': ['saga', 'liblinear'],\n",
    "    'lgr__penalty': ['l1', 'l2'],\n",
    "    'lgr__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "# Use stratify version of k-fold to keep class imbalance ratio\n",
    "k_fold = StratifiedKFold(n_splits=3, shuffle=True, random_state=2020)\n",
    "\n",
    "# Cross Validation\n",
    "# lg_grid = GridSearchCV(pipeline, param_grid=param_grid, cv=k_fold, n_jobs=-1, return_train_score=True, scoring='roc_auc')\n",
    "lg_rndm = RandomizedSearchCV(pipeline, param_distributions=param_grid, cv=k_fold, n_jobs=-1, return_train_score=True, scoring='f1')\n",
    "\n",
    "# Train with balanced classes\n",
    "grid_result = lg_rndm.fit(X_train_under, y_train_under)\n",
    "\n",
    "# Summarize results\n",
    "print(f'Best Score: {round(grid_result.best_score_, 3)}\\nParams: {grid_result.best_params_}\\n')\n",
    "\n",
    "mean_train = grid_result.cv_results_['mean_train_score']\n",
    "mean_test = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean_tr, mean_ts, param in zip(mean_train, mean_test, params):\n",
    "    print(f'Train {round(mean_tr, 3)}\\tTest {round(mean_ts, 3)}\\tParams: {param}')\n",
    "    \n",
    "# # Examine the best model\n",
    "# print(lg_grid.best_score_)\n",
    "# print(lg_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 0.74\n",
      "ROC_AUC   : 0.741\n",
      "Precision : 0.432\n",
      "Recall    : 0.741\n",
      "F-score   : 0.546\n",
      "\n",
      "Confusion Matrix\n",
      "[[61912 21741]\n",
      " [ 5778 16523]]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model with best paramaters\n",
    "lgr_best = LogisticRegression(C=10, penalty='l2', solver='saga', random_state=2020)\n",
    "\n",
    "# Train with balanced classes\n",
    "lgr_best.fit(X_train_under, y_train_under)\n",
    "\n",
    "# Get predictions\n",
    "lgr_best_preds = lgr_best.predict(X_test)\n",
    "# lgr_best_y_score = lgr_best.predict_proba(X_test)\n",
    "\n",
    "# Get ROC AUC Score, precision, recall, f1-score\n",
    "accuracy  = round(accuracy_score(y_test, lgr_best_preds), 3)\n",
    "roc_auc   = round(roc_auc_score(y_test, lgr_best_preds), 3)\n",
    "precision = round(precision_score(y_test, lgr_best_preds), 3)\n",
    "recall    = round(recall_score(y_test, lgr_best_preds), 3)\n",
    "f1        = round(f1_score(y_test, lgr_best_preds), 3)\n",
    "\n",
    "print(f'Accuracy  : {accuracy}')\n",
    "print(f'ROC_AUC   : {roc_auc}')\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall    : {recall}')\n",
    "print(f'F-score   : {f1}')\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\nConfusion Matrix\\n' + str(confusion_matrix(y_test, lgr_best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/lgr_best.sav']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add model and accuracy dict to list\n",
    "model_performance.append(dict([\n",
    "    ('Model', 'Logistic Regression'),\n",
    "    ('ROC AUC', round(roc_auc, 3)),\n",
    "    ('Precision', round(precision, 3)),\n",
    "    ('Recall', round(recall, 3)),\n",
    "    ('F1', round(f1, 3))\n",
    "     ]))\n",
    "\n",
    "# Save model for later use\n",
    "joblib.dump(lgr_best, '../models/lgr_best.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.745\n",
      "Params: {'und__random_state': 2020, 'knn__n_neighbors': 7}\n",
      "\n",
      "Train 0.852\tTest 0.731\tParams: {'und__random_state': 2020, 'knn__n_neighbors': 3}\n",
      "Train 0.82\tTest 0.74\tParams: {'und__random_state': 2020, 'knn__n_neighbors': 5}\n",
      "Train 0.805\tTest 0.745\tParams: {'und__random_state': 2020, 'knn__n_neighbors': 7}\n"
     ]
    }
   ],
   "source": [
    "# Grid searching key hyperparameters for KNN\n",
    "\n",
    "# Instantiate model and RandomUnderSampler\n",
    "knn_model = KNeighborsClassifier()\n",
    "under = RandomUnderSampler(random_state=2020)\n",
    "\n",
    "# Construct pipeline\n",
    "steps = [('und', under), ('knn', knn_model)]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Define parameter grid values to be searched\n",
    "param_grid = {\n",
    "    'und__random_state': [2020],\n",
    "    'knn__n_neighbors' : [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Use stratify version of k-fold to keep class imbalance ratio\n",
    "k_fold = StratifiedKFold(n_splits=3, shuffle=True, random_state=2020)\n",
    "\n",
    "# Cross Validation\n",
    "# knn_grid = GridSearchCV(pipeline, param_grid=param_grid, cv=k_fold, n_jobs=-1, return_train_score=True, scoring='roc_auc')\n",
    "knn_rndm = RandomizedSearchCV(pipeline, param_distributions=param_grid, cv=k_fold, n_jobs=-1, return_train_score=True, scoring='f1')\n",
    "\n",
    "# Train with balanced classes\n",
    "grid_result = knn_rndm.fit(X_train_under, y_train_under) # Should I use X_train, y_train here?\n",
    "\n",
    "# Summarize results\n",
    "print(f'Best Score: {round(grid_result.best_score_, 3)}\\nParams: {grid_result.best_params_}\\n')\n",
    "\n",
    "mean_train = grid_result.cv_results_['mean_train_score']\n",
    "mean_test = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean_tr, mean_ts, param in zip(mean_train, mean_test, params):\n",
    "    print(f'Train {round(mean_tr, 3)}\\tTest {round(mean_ts, 3)}\\tParams: {param}')\n",
    "    \n",
    "# # Examine the best model\n",
    "# print(knn_grid.best_score_)\n",
    "# print(knn_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 0.732\n",
      "ROC_AUC   : 0.743\n",
      "Precision : 0.424\n",
      "Recall    : 0.761\n",
      "F-score   : 0.544\n",
      "\n",
      "Confusion Matrix\n",
      "[[60605 23048]\n",
      " [ 5339 16962]]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model with best paramaters\n",
    "knn_best = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "# Train with balanced classes\n",
    "knn_best.fit(X_train_under, y_train_under)\n",
    "\n",
    "# Get predictions\n",
    "knn_best_preds = knn_best.predict(X_test)\n",
    "# knn_best_y_score = knn_best.predict_proba(X_test)\n",
    "\n",
    "# Get ROC AUC Score, precision, recall, f1-score\n",
    "accuracy  = round(accuracy_score(y_test,  knn_best_preds), 3)\n",
    "roc_auc   = round(roc_auc_score(y_test,   knn_best_preds), 3)\n",
    "precision = round(precision_score(y_test, knn_best_preds), 3)\n",
    "recall    = round(recall_score(y_test,    knn_best_preds), 3)\n",
    "f1        = round(f1_score(y_test,        knn_best_preds), 3)\n",
    "\n",
    "print(f'Accuracy  : {accuracy}')\n",
    "print(f'ROC_AUC   : {roc_auc}')\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall    : {recall}')\n",
    "print(f'F-score   : {f1}')\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\nConfusion Matrix\\n' + str(confusion_matrix(y_test, knn_best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/knn_best.sav']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add model and accuracy dict to list\n",
    "model_performance.append(dict([\n",
    "    ('Model', 'KNN'),\n",
    "    ('ROC AUC', round(roc_auc, 3)),\n",
    "    ('Precision', round(precision, 3)),\n",
    "    ('Recall', round(recall, 3)),\n",
    "    ('F1', round(f1, 3))\n",
    "     ]))\n",
    "\n",
    "# Save model for later use\n",
    "joblib.dump(knn_best, '../models/knn_best.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.726\n",
      "Params: {'und__random_state': 2020, 'rfc__random_state': 2020, 'rfc__n_estimators': 100, 'rfc__max_features': 5, 'rfc__max_depth': 2, 'rfc__criterion': 'gini'}\n",
      "\n",
      "Train 0.701\tTest 0.701\tParams: {'und__random_state': 2020, 'rfc__random_state': 2020, 'rfc__n_estimators': 100, 'rfc__max_features': 15, 'rfc__max_depth': 4, 'rfc__criterion': 'gini'}\n",
      "Train 0.694\tTest 0.694\tParams: {'und__random_state': 2020, 'rfc__random_state': 2020, 'rfc__n_estimators': 200, 'rfc__max_features': 15, 'rfc__max_depth': 3, 'rfc__criterion': 'entropy'}\n",
      "Train 0.706\tTest 0.706\tParams: {'und__random_state': 2020, 'rfc__random_state': 2020, 'rfc__n_estimators': 1000, 'rfc__max_features': 15, 'rfc__max_depth': 3, 'rfc__criterion': 'gini'}\n",
      "Train 0.698\tTest 0.697\tParams: {'und__random_state': 2020, 'rfc__random_state': 2020, 'rfc__n_estimators': 50, 'rfc__max_features': 10, 'rfc__max_depth': 3, 'rfc__criterion': 'entropy'}\n",
      "Train 0.726\tTest 0.726\tParams: {'und__random_state': 2020, 'rfc__random_state': 2020, 'rfc__n_estimators': 100, 'rfc__max_features': 5, 'rfc__max_depth': 2, 'rfc__criterion': 'gini'}\n",
      "Train 0.719\tTest 0.718\tParams: {'und__random_state': 2020, 'rfc__random_state': 2020, 'rfc__n_estimators': 1000, 'rfc__max_features': 5, 'rfc__max_depth': 2, 'rfc__criterion': 'entropy'}\n",
      "Train 0.711\tTest 0.712\tParams: {'und__random_state': 2020, 'rfc__random_state': 2020, 'rfc__n_estimators': 50, 'rfc__max_features': 10, 'rfc__max_depth': 4, 'rfc__criterion': 'entropy'}\n",
      "Train 0.725\tTest 0.724\tParams: {'und__random_state': 2020, 'rfc__random_state': 2020, 'rfc__n_estimators': 1000, 'rfc__max_features': 5, 'rfc__max_depth': 4, 'rfc__criterion': 'gini'}\n",
      "Train 0.704\tTest 0.704\tParams: {'und__random_state': 2020, 'rfc__random_state': 2020, 'rfc__n_estimators': 100, 'rfc__max_features': 10, 'rfc__max_depth': 3, 'rfc__criterion': 'entropy'}\n",
      "Train 0.713\tTest 0.713\tParams: {'und__random_state': 2020, 'rfc__random_state': 2020, 'rfc__n_estimators': 1000, 'rfc__max_features': 10, 'rfc__max_depth': 4, 'rfc__criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "# Grid searching key hyperparameters for Random Forest\n",
    "\n",
    "# Instantiate model and RandomUnderSampler\n",
    "rf_model = RandomForestClassifier()\n",
    "under = RandomUnderSampler(random_state=2020)\n",
    "\n",
    "# Construct pipeline\n",
    "steps = [('und', under), ('rfc', rf_model)]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Define parameter grid values to be searched\n",
    "param_grid = {\n",
    "    'und__random_state': [2020],\n",
    "    'rfc__n_estimators': [50, 100, 150, 200, 1000],\n",
    "    'rfc__max_depth' : [2, 3, 4],\n",
    "    'rfc__max_features' : [5, 10, 15],\n",
    "    'rfc__criterion' : ['gini', 'entropy'],\n",
    "    'rfc__random_state' :[2020]\n",
    "}\n",
    "\n",
    "# Use stratify version of k-fold to keep class imbalance ratio\n",
    "k_fold = StratifiedKFold(n_splits=3, shuffle=True, random_state=2020)\n",
    "\n",
    "# Cross Validation\n",
    "# rf_grid = GridSearchCV(pipeline, param_grid=param_grid, cv=k_fold, n_jobs=-1, return_train_score=True, scoring='roc_auc')\n",
    "rf_rndm = RandomizedSearchCV(pipeline, param_distributions=param_grid, cv=k_fold, n_jobs=-1, return_train_score=True, scoring='f1')\n",
    "\n",
    "# Train with balanced classes\n",
    "grid_result = rf_rndm.fit(X_train_under, y_train_under) # Should I use X_train, y_train here?\n",
    "\n",
    "# Summarize results\n",
    "print(f'Best Score: {round(grid_result.best_score_, 3)}\\nParams: {grid_result.best_params_}\\n')\n",
    "\n",
    "mean_train = grid_result.cv_results_['mean_train_score']\n",
    "mean_test = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean_tr, mean_ts, param in zip(mean_train, mean_test, params):\n",
    "    print(f'Train {round(mean_tr, 3)}\\tTest {round(mean_ts, 3)}\\tParams: {param}')\n",
    "    \n",
    "# # Examine the best model\n",
    "# print(rf_grid.best_score_)\n",
    "# print(rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 0.654\n",
      "ROC_AUC   : 0.702\n",
      "Precision : 0.354\n",
      "Recall    : 0.784\n",
      "F-score   : 0.488\n",
      "\n",
      "Confusion Matrix\n",
      "[[51788 31865]\n",
      " [ 4806 17495]]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model with best paramaters\n",
    "rfc_best = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=2, max_features=5, random_state=2020)\n",
    "\n",
    "# Train with balanced classes\n",
    "rfc_best.fit(X_train_under, y_train_under)\n",
    "\n",
    "# Get predictions\n",
    "rfc_best_preds = rfc_best.predict(X_test)\n",
    "# rfc_best_y_score = rfc_best.predict_proba(X_test)\n",
    "\n",
    "# Get ROC AUC Score, precision, recall, f1-score\n",
    "accuracy  = round(accuracy_score(y_test,  rfc_best_preds), 3)\n",
    "roc_auc   = round(roc_auc_score(y_test,   rfc_best_preds), 3)\n",
    "precision = round(precision_score(y_test, rfc_best_preds), 3)\n",
    "recall    = round(recall_score(y_test,    rfc_best_preds), 3)\n",
    "f1        = round(f1_score(y_test,        rfc_best_preds), 3)\n",
    "\n",
    "print(f'Accuracy  : {accuracy}')\n",
    "print(f'ROC_AUC   : {roc_auc}')\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall    : {recall}')\n",
    "print(f'F-score   : {f1}')\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\nConfusion Matrix\\n' + str(confusion_matrix(y_test, rfc_best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/rfc_best.sav']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add model and accuracy dict to list\n",
    "model_performance.append(dict([\n",
    "    ('Model', 'Random Forest'),\n",
    "    ('ROC AUC', round(roc_auc, 3)),\n",
    "    ('Precision', round(precision, 3)),\n",
    "    ('Recall', round(recall, 3)),\n",
    "    ('F1', round(f1, 3))\n",
    "     ]))\n",
    "\n",
    "# Save model for later use\n",
    "joblib.dump(rfc_best, '../models/rfc_best.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.82\n",
      "Params: {'xgb__n_estimators': 1000, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.1, 'und__random_state': 2020}\n",
      "\n",
      "Train 0.798\tTest 0.795\tParams: {'xgb__n_estimators': 500, 'xgb__max_depth': 3, 'xgb__learning_rate': 0.1, 'und__random_state': 2020}\n",
      "Train 0.811\tTest 0.806\tParams: {'xgb__n_estimators': 1000, 'xgb__max_depth': 3, 'xgb__learning_rate': 0.1, 'und__random_state': 2020}\n",
      "Train 0.81\tTest 0.804\tParams: {'xgb__n_estimators': 500, 'xgb__max_depth': 4, 'xgb__learning_rate': 0.1, 'und__random_state': 2020}\n",
      "Train 0.826\tTest 0.815\tParams: {'xgb__n_estimators': 1000, 'xgb__max_depth': 4, 'xgb__learning_rate': 0.1, 'und__random_state': 2020}\n",
      "Train 0.824\tTest 0.814\tParams: {'xgb__n_estimators': 500, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.1, 'und__random_state': 2020}\n",
      "Train 0.839\tTest 0.82\tParams: {'xgb__n_estimators': 1000, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.1, 'und__random_state': 2020}\n"
     ]
    }
   ],
   "source": [
    "# Grid searching key hyperparameters for XGBoost\n",
    "# Instantiate model and RandomUnderSampler\n",
    "xgb_model = XGBClassifier()\n",
    "under = RandomUnderSampler(random_state=2020)\n",
    "\n",
    "# Construct pipeline\n",
    "steps = [('und', under), ('xgb', xgb_model)]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Define parameter grid values to be searched\n",
    "param_grid = {\n",
    "    'und__random_state': [2020],\n",
    "    'xgb__n_estimators': [100, 250, 500, 1000], \n",
    "    'xgb__max_depth': [3, 4, 5], \n",
    "    'xgb__learning_rate': [0.1] # 0.001, 0.01, \n",
    "}\n",
    "\n",
    "# Use stratify version of k-fold to keep class imbalance ratio\n",
    "k_fold = StratifiedKFold(n_splits=3, shuffle=True, random_state=2020)\n",
    "\n",
    "# Cross Validation\n",
    "# xgb_grid = GridSearchCV(pipeline, param_grid=param_grid, cv=k_fold, n_jobs=-1, return_train_score=True, scoring='roc_auc')\n",
    "xgb_rndm = RandomizedSearchCV(pipeline, param_distributions=param_grid, cv=3, n_jobs=-1, return_train_score=True, scoring='f1')\n",
    "# # Dask HyperbandSearchCV\n",
    "# search = HyperbandSearchCV(xgb_model, param_grid, max_iter=3, patience=True)\n",
    "\n",
    "# Train with balanced classes\n",
    "grid_result = xgb_rndm.fit(X_train_under, y_train_under)\n",
    "\n",
    "# Summarize results\n",
    "print(f'Best Score: {round(grid_result.best_score_, 3)}\\nParams: {grid_result.best_params_}\\n')\n",
    "\n",
    "mean_train = grid_result.cv_results_['mean_train_score']\n",
    "mean_test = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean_tr, mean_ts, param in zip(mean_train, mean_test, params):\n",
    "    print(f'Train {round(mean_tr, 3)}\\tTest {round(mean_ts, 3)}\\tParams: {param}')\n",
    "\n",
    "# # Examine the best model\n",
    "# print(lg_grid.best_score_)\n",
    "# print(lg_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 0.834\n",
      "ROC_AUC   : 0.824\n",
      "Precision : 0.576\n",
      "Recall    : 0.807\n",
      "F-score   : 0.672\n",
      "\n",
      "Confusion Matrix\n",
      "[[70383 13270]\n",
      " [ 4300 18001]]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model with best paramaters\n",
    "xgb_best = XGBClassifier(n_estimators=1000, max_depth=5, learning_rate=0.1)\n",
    "\n",
    "# Train with balanced classes\n",
    "xgb_best.fit(X_train_under, y_train_under)\n",
    "\n",
    "# Get predictions\n",
    "xgb_best_preds = xgb_best.predict(X_test)\n",
    "# xgb_best_y_score = xgb_best.predict_proba(X_test)\n",
    "\n",
    "# Get ROC AUC Score, precision, recall, f1-score\n",
    "accuracy  = round(accuracy_score(y_test,  xgb_best_preds), 3)\n",
    "roc_auc   = round(roc_auc_score(y_test,   xgb_best_preds), 3)\n",
    "precision = round(precision_score(y_test, xgb_best_preds), 3)\n",
    "recall    = round(recall_score(y_test,    xgb_best_preds), 3)\n",
    "f1        = round(f1_score(y_test,        xgb_best_preds), 3)\n",
    "\n",
    "print(f'Accuracy  : {accuracy}')\n",
    "print(f'ROC_AUC   : {roc_auc}')\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall    : {recall}')\n",
    "print(f'F-score   : {f1}')\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\nConfusion Matrix\\n' + str(confusion_matrix(y_test, xgb_best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Add model and accuracy dict to list\n",
    "model_performance.append(dict([\n",
    "    ('Model', 'XGBoost'),\n",
    "    ('ROC AUC', round(roc_auc, 3)),\n",
    "    ('Precision', round(precision, 3)),\n",
    "    ('Recall', round(recall, 3)),\n",
    "    ('F1', round(f1, 3))\n",
    "     ]))\n",
    "\n",
    "# Save model for later use\n",
    "joblib.dump(xgb_best, '../models/xgb_best.sav')\n",
    "\n",
    "# Save predictions for later use\n",
    "with open('../data/04_xgb_best_preds.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_best_preds, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "ensemble = VotingClassifier(estimators=[('lrg', lgr_best), ('rfc', rfc_best), ('xgb', xgb_best)], voting='soft', weights=[1, 1, 1])\n",
    "\n",
    "# Train with balanced classes\n",
    "ensemble.fit(X_train_under, y_train_under)\n",
    "\n",
    "# Get predictions\n",
    "ensemble_preds = ensemble.predict(X_test)\n",
    "# xgb_best_y_score = xgb_best.predict_proba(X_test)\n",
    "\n",
    "# Get ROC AUC Score, precision, recall, f1-score\n",
    "accuracy  = round(accuracy_score(y_test,  ensemble), 3)\n",
    "roc_auc   = round(roc_auc_score(y_test,   ensemble), 3)\n",
    "precision = round(precision_score(y_test, ensemble), 3)\n",
    "recall    = round(recall_score(y_test,    ensemble), 3)\n",
    "f1        = round(f1_score(y_test,        ensemble), 3)\n",
    "\n",
    "print(f'Accuracy  : {accuracy}')\n",
    "print(f'ROC_AUC   : {roc_auc}')\n",
    "print(f'Precision : {precision}')\n",
    "print(f'Recall    : {recall}')\n",
    "print(f'F-score   : {f1}')\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\nConfusion Matrix\\n' + str(confusion_matrix(y_test, ensemble)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Add model and accuracy dict to list\n",
    "model_performance.append(dict([\n",
    "    ('Model', 'Ensemble'),\n",
    "    ('ROC AUC', round(roc_auc, 3)),\n",
    "    ('Precision', round(precision, 3)),\n",
    "    ('Recall', round(recall, 3)),\n",
    "    ('F1', round(f1, 3))\n",
    "     ]))\n",
    "\n",
    "# Save model for later use\n",
    "joblib.dump(xgb_best, '../models/ensemble.sav')\n",
    "\n",
    "# Save predictions for later use\n",
    "with open('../data/04_ensemble_preds.pkl', 'wb') as f:\n",
    "    pickle.dump(ensemble_preds, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Pickel model performance\n",
    "with open('../data/04_model_performance.pkl', 'wb') as f:\n",
    "    pickle.dump(model_performance, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# cat /proc/cpuinfo\n",
    "\n",
    "# # Import Dask libraries\n",
    "\n",
    "# from dask import delayed\n",
    "# import joblib\n",
    "# import dask.dataframe as dd\n",
    "# import dask.array as da\n",
    "\n",
    "# from dask_ml.model_selection import train_test_split\n",
    "# from dask_ml.linear_model import LogisticRegression\n",
    "# from dask_ml.xgboost import XGBClassifier\n",
    "# from dask_ml.model_selection import RandomizedSearchCV\n",
    "# from dask_ml.model_selection import HyperbandSearchCV \n",
    "# # HyperbandSearchCVis Dask-ML’s meta-estimator to find the best hyperparameters.\n",
    "# # It can be used as an alternative to RandomizedSearchCV to find similar hyper-parameters\n",
    "# # in less time by not wasting time on hyper-parameters that are not promising. \n",
    "\n",
    "# from dask.distributed import Client, progress\n",
    "# from sklearn.externals.joblib import parallel_backend\n",
    "\n",
    "# client = Client(processes=False)\n",
    "# # client = Client(processes=False, n_workers=4, threads_per_worker=8)\n",
    "# client\n",
    "# # client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
