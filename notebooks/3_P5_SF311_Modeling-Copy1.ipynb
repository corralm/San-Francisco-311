{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Todos\n",
    "* Recursive Feature Elimination\n",
    "    * from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Add table of contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tools\n",
    "from collections import Counter\n",
    "import pickle\n",
    "# import joblib\n",
    "# svc_model = joblib.load('../models/SVC_20k.pkl')\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score, fbeta_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Model Prep & Selection\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Visualizations\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Train and Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>opened</th>\n",
       "      <th>closed</th>\n",
       "      <th>updated</th>\n",
       "      <th>status_notes</th>\n",
       "      <th>responsible_agency</th>\n",
       "      <th>category</th>\n",
       "      <th>request_type</th>\n",
       "      <th>request_details</th>\n",
       "      <th>...</th>\n",
       "      <th>source</th>\n",
       "      <th>opened_year</th>\n",
       "      <th>opened_month_sin</th>\n",
       "      <th>opened_month_cos</th>\n",
       "      <th>opened_week_sin</th>\n",
       "      <th>opened_week_cos</th>\n",
       "      <th>opened_day_sin</th>\n",
       "      <th>opened_day_cos</th>\n",
       "      <th>opened_hour_sin</th>\n",
       "      <th>opened_hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>11879423</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-30 20:54:00</td>\n",
       "      <td>2020-01-03 11:59:19</td>\n",
       "      <td>2020-01-03 11:59:19</td>\n",
       "      <td>Agencies responded to request and no encampmen...</td>\n",
       "      <td>Duplicate Case Hold Queue</td>\n",
       "      <td>Encampments</td>\n",
       "      <td>Encampment Reports</td>\n",
       "      <td>Encampment Cleanup</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobile/Open311</td>\n",
       "      <td>2019</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>11877576</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-30 13:31:54</td>\n",
       "      <td>2019-12-31 13:42:03</td>\n",
       "      <td>2019-12-31 13:42:03</td>\n",
       "      <td>Case Resolved - SES Graffiti Crew  - Remove Si...</td>\n",
       "      <td>DPW Ops Queue</td>\n",
       "      <td>Illegal Postings</td>\n",
       "      <td>Illegal Postings - Affixed_Improperly</td>\n",
       "      <td>Affixed Improperly</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobile/Open311</td>\n",
       "      <td>2019</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>11877532</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-30 13:26:00</td>\n",
       "      <td>2019-12-30 14:03:00</td>\n",
       "      <td>2019-12-30 14:03:00</td>\n",
       "      <td>Case Resolved</td>\n",
       "      <td>DPW Ops Queue</td>\n",
       "      <td>Street and Sidewalk Cleaning</td>\n",
       "      <td>General Cleaning</td>\n",
       "      <td>Other Loose Garbage</td>\n",
       "      <td>...</td>\n",
       "      <td>Phone</td>\n",
       "      <td>2019</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>11877496</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-30 13:22:00</td>\n",
       "      <td>2019-12-30 18:53:45</td>\n",
       "      <td>2019-12-30 18:53:45</td>\n",
       "      <td>Case Resolved - WASTE NOT FOUND               ...</td>\n",
       "      <td>Recology_Abandoned</td>\n",
       "      <td>Street and Sidewalk Cleaning</td>\n",
       "      <td>Bulky Items</td>\n",
       "      <td>Refrigerator</td>\n",
       "      <td>...</td>\n",
       "      <td>Phone</td>\n",
       "      <td>2019</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>11877234</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-30 12:45:38</td>\n",
       "      <td>2020-01-02 07:17:00</td>\n",
       "      <td>2020-01-02 07:17:00</td>\n",
       "      <td>Case Resolved</td>\n",
       "      <td>DPW Ops Queue</td>\n",
       "      <td>Street and Sidewalk Cleaning</td>\n",
       "      <td>General Cleaning</td>\n",
       "      <td>Other Loose Garbage</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobile/Open311</td>\n",
       "      <td>2019</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      case_id  is_duplicate              opened              closed  \\\n",
       "619  11879423             0 2019-12-30 20:54:00 2020-01-03 11:59:19   \n",
       "620  11877576             0 2019-12-30 13:31:54 2019-12-31 13:42:03   \n",
       "621  11877532             0 2019-12-30 13:26:00 2019-12-30 14:03:00   \n",
       "622  11877496             0 2019-12-30 13:22:00 2019-12-30 18:53:45   \n",
       "623  11877234             0 2019-12-30 12:45:38 2020-01-02 07:17:00   \n",
       "\n",
       "                updated                                       status_notes  \\\n",
       "619 2020-01-03 11:59:19  Agencies responded to request and no encampmen...   \n",
       "620 2019-12-31 13:42:03  Case Resolved - SES Graffiti Crew  - Remove Si...   \n",
       "621 2019-12-30 14:03:00                                      Case Resolved   \n",
       "622 2019-12-30 18:53:45  Case Resolved - WASTE NOT FOUND               ...   \n",
       "623 2020-01-02 07:17:00                                      Case Resolved   \n",
       "\n",
       "            responsible_agency                      category  \\\n",
       "619  Duplicate Case Hold Queue                   Encampments   \n",
       "620              DPW Ops Queue              Illegal Postings   \n",
       "621              DPW Ops Queue  Street and Sidewalk Cleaning   \n",
       "622         Recology_Abandoned  Street and Sidewalk Cleaning   \n",
       "623              DPW Ops Queue  Street and Sidewalk Cleaning   \n",
       "\n",
       "                              request_type      request_details  ...  \\\n",
       "619                     Encampment Reports   Encampment Cleanup  ...   \n",
       "620  Illegal Postings - Affixed_Improperly   Affixed Improperly  ...   \n",
       "621                       General Cleaning  Other Loose Garbage  ...   \n",
       "622                            Bulky Items         Refrigerator  ...   \n",
       "623                       General Cleaning  Other Loose Garbage  ...   \n",
       "\n",
       "             source opened_year opened_month_sin opened_month_cos  \\\n",
       "619  Mobile/Open311        2019    -2.449294e-16              1.0   \n",
       "620  Mobile/Open311        2019    -2.449294e-16              1.0   \n",
       "621           Phone        2019    -2.449294e-16              1.0   \n",
       "622           Phone        2019    -2.449294e-16              1.0   \n",
       "623  Mobile/Open311        2019    -2.449294e-16              1.0   \n",
       "\n",
       "    opened_week_sin  opened_week_cos  opened_day_sin opened_day_cos  \\\n",
       "619        0.120537         0.992709             0.0            1.0   \n",
       "620        0.120537         0.992709             0.0            1.0   \n",
       "621        0.120537         0.992709             0.0            1.0   \n",
       "622        0.120537         0.992709             0.0            1.0   \n",
       "623        0.120537         0.992709             0.0            1.0   \n",
       "\n",
       "    opened_hour_sin opened_hour_cos  \n",
       "619   -8.660254e-01        0.500000  \n",
       "620   -2.588190e-01       -0.965926  \n",
       "621   -2.588190e-01       -0.965926  \n",
       "622   -2.588190e-01       -0.965926  \n",
       "623    1.224647e-16       -1.000000  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataframe\n",
    "df = pd.read_pickle('../data/df_cyclical_features_20k.pkl')\n",
    "\n",
    "# # TEMPORARY\n",
    "# df = df.sample(5000)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>opened_month_sin</th>\n",
       "      <th>opened_month_cos</th>\n",
       "      <th>opened_week_sin</th>\n",
       "      <th>opened_week_cos</th>\n",
       "      <th>opened_day_sin</th>\n",
       "      <th>opened_day_cos</th>\n",
       "      <th>opened_hour_sin</th>\n",
       "      <th>opened_hour_cos</th>\n",
       "      <th>...</th>\n",
       "      <th>opened_year_2010</th>\n",
       "      <th>opened_year_2011</th>\n",
       "      <th>opened_year_2012</th>\n",
       "      <th>opened_year_2013</th>\n",
       "      <th>opened_year_2014</th>\n",
       "      <th>opened_year_2015</th>\n",
       "      <th>opened_year_2016</th>\n",
       "      <th>opened_year_2017</th>\n",
       "      <th>opened_year_2018</th>\n",
       "      <th>opened_year_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19476</th>\n",
       "      <td>37.784027</td>\n",
       "      <td>-122.409607</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>-2.393157e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>37.770302</td>\n",
       "      <td>-122.450912</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>1.205367e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10155</th>\n",
       "      <td>37.720915</td>\n",
       "      <td>-122.435768</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-0.822984</td>\n",
       "      <td>-5.680647e-01</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7455</th>\n",
       "      <td>37.764227</td>\n",
       "      <td>-122.410453</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14313</th>\n",
       "      <td>37.747768</td>\n",
       "      <td>-122.403488</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>-6.631227e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1658 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        latitude   longitude  opened_month_sin  opened_month_cos  \\\n",
       "19476  37.784027 -122.409607          0.866025     -5.000000e-01   \n",
       "4602   37.770302 -122.450912         -0.866025      5.000000e-01   \n",
       "10155  37.720915 -122.435768         -0.866025     -5.000000e-01   \n",
       "7455   37.764227 -122.410453         -1.000000     -1.836970e-16   \n",
       "14313  37.747768 -122.403488          0.500000     -8.660254e-01   \n",
       "\n",
       "       opened_week_sin  opened_week_cos  opened_day_sin  opened_day_cos  \\\n",
       "19476         0.970942    -2.393157e-01        0.000000        1.000000   \n",
       "4602         -0.992709     1.205367e-01        0.000000        1.000000   \n",
       "10155        -0.822984    -5.680647e-01        0.433884       -0.900969   \n",
       "7455         -1.000000    -1.836970e-16        0.974928       -0.222521   \n",
       "14313         0.748511    -6.631227e-01        0.000000        1.000000   \n",
       "\n",
       "       opened_hour_sin  opened_hour_cos  ...  opened_year_2010  \\\n",
       "19476    -2.588190e-01        -0.965926  ...                 0   \n",
       "4602      2.588190e-01        -0.965926  ...                 0   \n",
       "10155     8.660254e-01        -0.500000  ...                 0   \n",
       "7455      1.224647e-16        -1.000000  ...                 0   \n",
       "14313    -2.588190e-01        -0.965926  ...                 0   \n",
       "\n",
       "       opened_year_2011  opened_year_2012  opened_year_2013  opened_year_2014  \\\n",
       "19476                 0                 0                 0                 0   \n",
       "4602                  0                 0                 0                 0   \n",
       "10155                 0                 0                 0                 0   \n",
       "7455                  0                 0                 0                 0   \n",
       "14313                 0                 0                 0                 1   \n",
       "\n",
       "       opened_year_2015  opened_year_2016  opened_year_2017  opened_year_2018  \\\n",
       "19476                 0                 0                 0                 0   \n",
       "4602                  0                 0                 0                 1   \n",
       "10155                 0                 1                 0                 0   \n",
       "7455                  0                 0                 1                 0   \n",
       "14313                 0                 0                 0                 0   \n",
       "\n",
       "       opened_year_2019  \n",
       "19476                 0  \n",
       "4602                  0  \n",
       "10155                 0  \n",
       "7455                  0  \n",
       "14313                 0  \n",
       "\n",
       "[5 rows x 1658 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns to exclude\n",
    "exclude_cols = [\n",
    "    'is_duplicate', # Target variable\n",
    "    'case_id',\n",
    "    'opened', # Needs Feature Eng\n",
    "    'closed', # Needs Feature Eng\n",
    "    'updated',\n",
    "    'responsible_agency', # Needs NLP\n",
    "    'status_notes', # Needs NLP\n",
    "    'request_type', # Needs NLP\n",
    "    'request_details', # Needs NLP\n",
    "    'address', # Needs NLP\n",
    "#     'street', # Convert to 'category' type to get dummies\n",
    "    'point'\n",
    "]\n",
    "\n",
    "# # Scale data using MinMax scaler\n",
    "# # No need to standardize as all features are categorical (maybe scale lat/long....)\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# Predictor variables\n",
    "x_variables_df = df.drop(columns=exclude_cols, axis=0, inplace=False)\n",
    "\n",
    "# Get dummies for categorical variables\n",
    "X = pd.get_dummies(x_variables_df, drop_first=True)\n",
    "\n",
    "# Target variable\n",
    "y = df['is_duplicate']\n",
    "\n",
    "# Split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=2020, \n",
    "                                                    stratify=y,  # Stratify to keep same class ratios\n",
    "                                                    shuffle=True # Shuffle data since it's ordered chronologically\n",
    "                                                   )\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df\t (16786, 28)\n",
      "X_train\t (13428, 1658)\n",
      "X_test\t (3358, 1658)\n",
      "y_train\t (13428,)\n",
      "y_test\t (3358,)\n"
     ]
    }
   ],
   "source": [
    "print('df\\t', df.shape)\n",
    "print('X_train\\t', X_train.shape)\n",
    "print('X_test\\t', X_test.shape)\n",
    "print('y_train\\t', y_train.shape)\n",
    "print('y_test\\t', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Class Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 15824\n",
      "Class 1: 962\n",
      "Proportion: 16.45 : 1\n",
      "Percentage of Majority Class: 94.3\n"
     ]
    }
   ],
   "source": [
    "# Target variable\n",
    "target_count = df['is_duplicate'].value_counts()\n",
    "\n",
    "# Print class balance\n",
    "print(f'Class 0: {target_count[0]}')\n",
    "print(f'Class 1: {target_count[1]}')\n",
    "print(f'Proportion: {round(target_count[0] / target_count[1], 2)} : 1')\n",
    "print(f'Percentage of Majority Class: {round(target_count[0] / sum(target_count), 3)*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 12658, 1: 12658})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A ratio of .5 is saying that 50% of my data is simulated\n",
    "# Trevor noted that .2 would be good but let's try different ratios\n",
    "smote = SMOTE(random_state=2020)\n",
    "X_train_smote, y_train_smote = smote.fit_sample(X_train, y_train)\n",
    "Counter(y_train_smote)\n",
    "# pd.Series(y_train_smote).value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Objective: Maximize F1 Score as both recall and precision are equally important and the classes are imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Create list of model and performance\n",
    "model_performance = []\n",
    "models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "User RandomizedSearchCV instead:\n",
    "https://blog.usejournal.com/a-comparison-of-grid-search-and-randomized-search-using-scikit-learn-29823179bc85\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y actual\t: Counter({0: 3166, 1: 192})\n",
      "y predicted\t: Counter({0: 3358})\n",
      "Precision : 0.0\n",
      "Recall    : 0.0\n",
      "F-score   : 0.0\n",
      "\n",
      "Confusion Matrix\n",
      "[[3166    0]\n",
      " [ 192    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguel/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/miguel/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Dummy Classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier(strategy= 'most_frequent').fit(X_train_smote, y_train_smote)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#Distribution of y test\n",
    "print('y actual\\t:', Counter(y_test))\n",
    "\n",
    "#Distribution of y predicted\n",
    "print('y predicted\\t:', Counter(y_pred))\n",
    "\n",
    "print(f'Precision : {round(precision_score(y_test, y_pred), 4)}')\n",
    "print(f'Recall    : {round(recall_score(y_test, y_pred), 4)}')\n",
    "print(f'F-score   : {round(f1_score(y_test, y_pred), 4)}')\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\nConfusion Matrix\\n' + str(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# base_models = []\n",
    "\n",
    "# # Instantiate the models\n",
    "# base_models.append(('LogisticRegression', LogisticRegression(solver='saga')))\n",
    "# base_models.append(('SVC', SVC(gamma='auto')))\n",
    "# base_models.append(('KNeighbors', KNeighborsClassifier()))\n",
    "# base_models.append(('RandomForest', RandomForestClassifier(n_estimators=10)))\n",
    "# base_models.append(('XGBoost', XGBClassifier()))\n",
    "\n",
    "# cv_results = []\n",
    "# names = []\n",
    "\n",
    "# # Cross Validate - 5 fold\n",
    "# for name, model in base_models:\n",
    "#     names.append(name)\n",
    "#     cv_results.append(np.round_(cross_val_score(model, X_train_smote, y_train_smote, cv=5, scoring='f1'), 3))\n",
    "#     with open(f'../models/{name}_20k.pkl', 'wb') as f:\n",
    "#         pickle.dump(model, f)\n",
    "\n",
    "# for i in range(len(names)):\n",
    "#     print(names[i], round(cv_results[i].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.896\n",
      "Params: {'lgr__C': 1000, 'lgr__penalty': 'l1', 'lgr__solver': 'liblinear', 'smt__random_state': 2020}\n",
      "\n",
      "Train 0.667\tTest 0.666\tParams: {'lgr__C': 0.001, 'lgr__penalty': 'l1', 'lgr__solver': 'saga', 'smt__random_state': 2020}\n",
      "Train 0.667\tTest 0.666\tParams: {'lgr__C': 0.001, 'lgr__penalty': 'l1', 'lgr__solver': 'liblinear', 'smt__random_state': 2020}\n",
      "Train 0.742\tTest 0.74\tParams: {'lgr__C': 0.001, 'lgr__penalty': 'l2', 'lgr__solver': 'saga', 'smt__random_state': 2020}\n",
      "Train 0.742\tTest 0.74\tParams: {'lgr__C': 0.001, 'lgr__penalty': 'l2', 'lgr__solver': 'liblinear', 'smt__random_state': 2020}\n",
      "Train 0.731\tTest 0.73\tParams: {'lgr__C': 0.01, 'lgr__penalty': 'l1', 'lgr__solver': 'saga', 'smt__random_state': 2020}\n",
      "Train 0.732\tTest 0.731\tParams: {'lgr__C': 0.01, 'lgr__penalty': 'l1', 'lgr__solver': 'liblinear', 'smt__random_state': 2020}\n",
      "Train 0.778\tTest 0.774\tParams: {'lgr__C': 0.01, 'lgr__penalty': 'l2', 'lgr__solver': 'saga', 'smt__random_state': 2020}\n",
      "Train 0.785\tTest 0.78\tParams: {'lgr__C': 0.01, 'lgr__penalty': 'l2', 'lgr__solver': 'liblinear', 'smt__random_state': 2020}\n",
      "Train 0.774\tTest 0.771\tParams: {'lgr__C': 0.1, 'lgr__penalty': 'l1', 'lgr__solver': 'saga', 'smt__random_state': 2020}\n",
      "Train 0.805\tTest 0.799\tParams: {'lgr__C': 0.1, 'lgr__penalty': 'l1', 'lgr__solver': 'liblinear', 'smt__random_state': 2020}\n",
      "Train 0.79\tTest 0.786\tParams: {'lgr__C': 0.1, 'lgr__penalty': 'l2', 'lgr__solver': 'saga', 'smt__random_state': 2020}\n",
      "Train 0.846\tTest 0.835\tParams: {'lgr__C': 0.1, 'lgr__penalty': 'l2', 'lgr__solver': 'liblinear', 'smt__random_state': 2020}\n",
      "Train 0.79\tTest 0.785\tParams: {'lgr__C': 1, 'lgr__penalty': 'l1', 'lgr__solver': 'saga', 'smt__random_state': 2020}\n",
      "Train 0.899\tTest 0.884\tParams: {'lgr__C': 1, 'lgr__penalty': 'l1', 'lgr__solver': 'liblinear', 'smt__random_state': 2020}\n",
      "Train 0.792\tTest 0.787\tParams: {'lgr__C': 1, 'lgr__penalty': 'l2', 'lgr__solver': 'saga', 'smt__random_state': 2020}\n",
      "Train 0.893\tTest 0.877\tParams: {'lgr__C': 1, 'lgr__penalty': 'l2', 'lgr__solver': 'liblinear', 'smt__random_state': 2020}\n",
      "Train 0.792\tTest 0.787\tParams: {'lgr__C': 10, 'lgr__penalty': 'l1', 'lgr__solver': 'saga', 'smt__random_state': 2020}\n",
      "Train 0.909\tTest 0.894\tParams: {'lgr__C': 10, 'lgr__penalty': 'l1', 'lgr__solver': 'liblinear', 'smt__random_state': 2020}\n",
      "Train 0.792\tTest 0.787\tParams: {'lgr__C': 10, 'lgr__penalty': 'l2', 'lgr__solver': 'saga', 'smt__random_state': 2020}\n",
      "Train 0.906\tTest 0.89\tParams: {'lgr__C': 10, 'lgr__penalty': 'l2', 'lgr__solver': 'liblinear', 'smt__random_state': 2020}\n",
      "Train 0.792\tTest 0.787\tParams: {'lgr__C': 100, 'lgr__penalty': 'l1', 'lgr__solver': 'saga', 'smt__random_state': 2020}\n",
      "Train 0.91\tTest 0.896\tParams: {'lgr__C': 100, 'lgr__penalty': 'l1', 'lgr__solver': 'liblinear', 'smt__random_state': 2020}\n",
      "Train 0.792\tTest 0.787\tParams: {'lgr__C': 100, 'lgr__penalty': 'l2', 'lgr__solver': 'saga', 'smt__random_state': 2020}\n",
      "Train 0.909\tTest 0.894\tParams: {'lgr__C': 100, 'lgr__penalty': 'l2', 'lgr__solver': 'liblinear', 'smt__random_state': 2020}\n",
      "Train 0.792\tTest 0.787\tParams: {'lgr__C': 1000, 'lgr__penalty': 'l1', 'lgr__solver': 'saga', 'smt__random_state': 2020}\n",
      "Train 0.911\tTest 0.896\tParams: {'lgr__C': 1000, 'lgr__penalty': 'l1', 'lgr__solver': 'liblinear', 'smt__random_state': 2020}\n",
      "Train 0.792\tTest 0.787\tParams: {'lgr__C': 1000, 'lgr__penalty': 'l2', 'lgr__solver': 'saga', 'smt__random_state': 2020}\n",
      "Train 0.91\tTest 0.895\tParams: {'lgr__C': 1000, 'lgr__penalty': 'l2', 'lgr__solver': 'liblinear', 'smt__random_state': 2020}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguel/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Grid searching key hyperparameters for logistic regression\n",
    "\n",
    "# Instantiate model and SMOTE\n",
    "lg_model = LogisticRegression()\n",
    "smote = SMOTE(random_state=2020)\n",
    "\n",
    "# Construct pipeline\n",
    "steps = [('smt', smote), ('lgr', lg_model)]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Define parameter grid values to be searched\n",
    "param_grid = {\n",
    "    'smt__random_state': [2020],\n",
    "    'lgr__solver': ['saga', 'liblinear'],\n",
    "    'lgr__penalty': ['l1', 'l2'],\n",
    "    'lgr__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "# Use stratify version of k-fold to keep class imbalance ratio\n",
    "k_fold = StratifiedKFold(n_splits=3, shuffle = True, random_state=2020)\n",
    "\n",
    "# Cross Validation\n",
    "lg_grid = RandomizedSearchCV(pipeline, param_grid=param_grid, cv=k_fold, n_jobs=-1, return_train_score=True, scoring='roc_auc')\n",
    "\n",
    "# Train with balanced classes\n",
    "grid_result = lg_grid.fit(X_train_smote, y_train_smote) # Should I use X_train, y_train here?\n",
    "\n",
    "# Summarize results\n",
    "print(f'Best Score: {round(grid_result.best_score_, 3)}\\nParams: {grid_result.best_params_}\\n')\n",
    "\n",
    "mean_train = grid_result.cv_results_['mean_train_score']\n",
    "mean_test = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean_tr, mean_ts, param in zip(mean_train, mean_test, params):\n",
    "    print(f'Train {round(mean_tr, 3)}\\tTest {round(mean_ts, 3)}\\tParams: {param}')\n",
    "    \n",
    "# # Examine the best model\n",
    "# print(lg_grid.best_score_)\n",
    "# print(lg_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguel/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model with best paramaters\n",
    "lg_best = LogisticRegression(C=1000, penalty='l1', solver='liblinear', random_state=2020)\n",
    "\n",
    "# Train with balanced classes\n",
    "lg_best.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Get predictions\n",
    "lg_best_preds = lg_best.predict(X_test)\n",
    "# lg_best_y_score = lg_best.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC - Test\t0.62\n",
      "Precision\t0.534\n",
      "Recall\t\t0.62\n",
      "F-score\t\t0.513\n",
      "\n",
      "Confusion Matrix\n",
      "[[2409  757]\n",
      " [ 100   92]]\n"
     ]
    }
   ],
   "source": [
    "# Get ROC AUC Score, precision, recall, f1-score\n",
    "lg_best_roc_auc_test  = round(roc_auc_score(y_test, lg_best_preds), 3)\n",
    "print(f'ROC_AUC - Test\\t{lg_best_roc_auc_test}')\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, lg_best_preds, average='macro')\n",
    "print(f'Precision\\t{round(precision, 3)}')\n",
    "print(f'Recall\\t\\t{round(recall, 3)}')\n",
    "print(f'F-score\\t\\t{round(fscore, 3)}')\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\nConfusion Matrix\\n' + str(confusion_matrix(y_test, lg_best_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    ">Why are my scores high in the CV but much lower after using best params?\n",
    ">* The FP Rate is really high..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Add model and accuracy dict to list\n",
    "model_performance.append(dict([\n",
    "    ('Model', 'Logistic Regression'),\n",
    "#     ('Train ROC AUC', lg_best_roc_auc_train),\n",
    "    ('Test ROC AUC', lg_best_roc_auc_test),\n",
    "    ('Precision', round(precision, 3)),\n",
    "    ('Recall', round(recall, 3)),\n",
    "    ('F1', round(fscore, 3))\n",
    "     ]))\n",
    "\n",
    "# Add model to list\n",
    "models.append('Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Grid searching key hyperparameters for KNN\n",
    "\n",
    "# Instantiate model and SMOTE\n",
    "knn_model = KNeighborsClassifier()\n",
    "smote = SMOTE(random_state=2020)\n",
    "\n",
    "# Construct pipeline\n",
    "steps = [('smt', smote), ('knn', knn_model)]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Define parameter grid values to be searched\n",
    "param_grid = {\n",
    "    'smt__random_state': [2020],\n",
    "    'knn__n_neighbors' : [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Use stratify version of k-fold to keep class imbalance ratio\n",
    "k_fold = StratifiedKFold(n_splits=3, shuffle = True, random_state=2020)\n",
    "\n",
    "# Cross Validation\n",
    "knn_grid = RandomizedSearchCV(pipeline, param_grid=param_grid, cv=k_fold, n_jobs=-1, return_train_score=True, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.95\n",
      "Params: {'knn__n_neighbors': 7, 'smt__random_state': 2020}\n",
      "\n",
      "Train 1.0\tTest 0.925\tParams: {'knn__n_neighbors': 3, 'smt__random_state': 2020}\n",
      "Train 1.0\tTest 0.94\tParams: {'knn__n_neighbors': 5, 'smt__random_state': 2020}\n",
      "Train 1.0\tTest 0.95\tParams: {'knn__n_neighbors': 7, 'smt__random_state': 2020}\n"
     ]
    }
   ],
   "source": [
    "# Train with balanced classes\n",
    "grid_result = knn_grid.fit(X_train_smote, y_train_smote) # Should I use X_train, y_train here?\n",
    "\n",
    "# Summarize results\n",
    "print(f'Best Score: {round(grid_result.best_score_, 3)}\\nParams: {grid_result.best_params_}\\n')\n",
    "\n",
    "mean_train = grid_result.cv_results_['mean_train_score']\n",
    "mean_test = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean_tr, mean_ts, param in zip(mean_train, mean_test, params):\n",
    "    print(f'Train {round(mean_tr, 3)}\\tTest {round(mean_ts, 3)}\\tParams: {param}')\n",
    "    \n",
    "# # Examine the best model\n",
    "# print(knn_grid.best_score_)\n",
    "# print(knn_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Instantiate model with best paramaters\n",
    "knn_best = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "# Train with balanced classes\n",
    "knn_best.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Get predictions\n",
    "knn_best_preds = knn_best.predict(X_test)\n",
    "# knn_best_y_score = knn_best.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC - Test\t0.596\n",
      "Precision\t0.522\n",
      "Recall\t\t0.596\n",
      "F-score\t\t0.448\n",
      "\n",
      "Confusion Matrix\n",
      "[[1946 1220]\n",
      " [  81  111]]\n"
     ]
    }
   ],
   "source": [
    "# Get ROC AUC Score, precision, recall, f1-score\n",
    "knn_best_roc_auc_test  = round(roc_auc_score(y_test, knn_best_preds), 3)\n",
    "print(f'ROC_AUC - Test\\t{knn_best_roc_auc_test}')\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, knn_best_preds, average='macro')\n",
    "print(f'Precision\\t{round(precision, 3)}')\n",
    "print(f'Recall\\t\\t{round(recall, 3)}')\n",
    "print(f'F-score\\t\\t{round(fscore, 3)}')\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\nConfusion Matrix\\n' + str(confusion_matrix(y_test, knn_best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Add model and accuracy dict to list\n",
    "model_performaXGBClassifier.append(dict([\n",
    "    ('Model', 'KNN'),\n",
    "#     ('Train ROC AUC', knn_best_roc_auc_train),\n",
    "    ('Test ROC AUC', knn_best_roc_auc_test),\n",
    "    ('Precision', round(precision, 3)),\n",
    "    ('Recall', round(recall, 3)),\n",
    "    ('F1', round(fscore, 3))\n",
    "     ]))\n",
    "\n",
    "# Add model to list\n",
    "models.append('KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Grid searching key hyperparameters for Random Forest\n",
    "\n",
    "# Instantiate model and SMOTE\n",
    "rf_model = RandomForestClassifier()\n",
    "smote = SMOTE(random_state=2020)\n",
    "\n",
    "# Construct pipeline\n",
    "steps = [('smt', smote), ('rfc', rf_model)]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Define parameter grid values to be searched\n",
    "param_grid = {\n",
    "    'smt__random_state': [2020],\n",
    "    'rfc__n_estimators': [50, 100, 150, 200, 1000],\n",
    "    'rfc__max_depth' : [2, 3, 4],\n",
    "#     'rfc__max_features' : [5, 10, 15],\n",
    "#     'rfc__criterion' : ['gini', 'entropy'],\n",
    "    'rfc__random_state' :[2020]\n",
    "}\n",
    "\n",
    "# Use stratify version of k-fold to keep class imbalance ratio\n",
    "k_fold = StratifiedKFold(n_splits=3, shuffle = True, random_state=2020)\n",
    "\n",
    "# Cross Validation\n",
    "rf_grid = RandomizedSearchCV(pipeline, param_grid=param_grid, cv=k_fold, n_jobs=-1, return_train_score=True, scoring='roc_auc') # Try accuracy or F1\n",
    "\n",
    "# Train with balanced classes\n",
    "grid_result = rf_grid.fit(X_train_smote, y_train_smote) # Should I use X_train, y_train here?\n",
    "\n",
    "# Summarize results\n",
    "print(f'Best Score: {round(grid_result.best_score_, 3)}\\nParams: {grid_result.best_params_}\\n')\n",
    "\n",
    "mean_train = grid_result.cv_results_['mean_train_score']\n",
    "mean_test = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean_tr, mean_ts, param in zip(mean_train, mean_test, params):\n",
    "    print(f'Train {round(mean_tr, 3)}\\tTest {round(mean_ts, 3)}\\tParams: {param}')\n",
    "    \n",
    "# # Examine the best model\n",
    "# print(rf_grid.best_score_)\n",
    "# print(rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Instantiate model with best paramaters\n",
    "rf_best = RandomForestClassifier(max_depth=4, n_estimators=150, random_state=2020)\n",
    "\n",
    "# Train with balanced classes\n",
    "rf_best.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Get predictions\n",
    "rf_best_preds = knn_best.predict(X_test)\n",
    "# knn_best_y_score = rf_best.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC - Test\t0.596\n",
      "Precision\t0.522\n",
      "Recall\t\t0.596\n",
      "F-score\t\t0.448\n",
      "\n",
      "Confusion Matrix\n",
      "[[1946 1220]\n",
      " [  81  111]]\n"
     ]
    }
   ],
   "source": [
    "# Get ROC AUC Score, precision, recall, f1-score\n",
    "rf_best_roc_auc_test  = round(roc_auc_score(y_test, rf_best_preds), 3)\n",
    "print(f'ROC_AUC - Test\\t{rf_best_roc_auc_test}')\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, rf_best_preds, average='macro')\n",
    "print(f'Precision\\t{round(precision, 3)}')\n",
    "print(f'Recall\\t\\t{round(recall, 3)}')\n",
    "print(f'F-score\\t\\t{round(fscore, 3)}')\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\nConfusion Matrix\\n' + str(confusion_matrix(y_test, rf_best_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Grid searching key hyperparameters for XGBoost\n",
    "\n",
    "# Instantiate model and SMOTE\n",
    "xgb_model = XGBClassifier()\n",
    "smote = SMOTE(random_state=2020)\n",
    "\n",
    "# Construct pipeline\n",
    "steps = [('smt', smote), ('xgb', xgb_model)]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Define parameter grid values to be searched\n",
    "param_grid = {\n",
    "    'smt__random_state': [2020],\n",
    "    'xgb__n_estimators': [100, 250, 500, 1000], \n",
    "    'xgb__max_depth': [3, 4, 5], \n",
    "    'xgb__learning_rate': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Use stratify version of k-fold to keep class imbalance ratio\n",
    "k_fold = StratifiedKFold(n_splits=3, shuffle = True, random_state=2020)\n",
    "\n",
    "# Cross Validation\n",
    "xgb_grid = RandomizedSearchCV(pipeline, param_grid=param_grid, cv=k_fold, n_jobs=-1, return_train_score=True, scoring='roc_auc')\n",
    "\n",
    "# Train with balanced classes\n",
    "grid_result = xgb_grid.fit(X_train_smote, y_train_smote) # Should I use X_train, y_train here?\n",
    "\n",
    "# Summarize results\n",
    "print(f'Best Score: {round(grid_result.best_score_, 3)}\\nParams: {grid_result.best_params_}\\n')\n",
    "\n",
    "mean_train = grid_result.cv_results_['mean_train_score']\n",
    "mean_test = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean_tr, mean_ts, param in zip(mean_train, mean_test, params):\n",
    "    print(f'Train {round(mean_tr, 3)}\\tTest {round(mean_ts, 3)}\\tParams: {param}')\n",
    "    \n",
    "# # Examine the best model\n",
    "# print(lg_grid.best_score_)\n",
    "# print(lg_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Instantiate model with best paramaters\n",
    "xgb_best = XGB(\n",
    "\n",
    "# Train with balanced classes\n",
    "xgb_best.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Get predictions\n",
    "xgb_best_preds = xgb_best.predict(X_test)\n",
    "# xgb_best_y_score = xgb_best.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Get ROC AUC Score, precision, recall, f1-score\n",
    "xgb_best_roc_auc_test  = round(roc_auc_score(y_test, xgb_best_preds), 3)\n",
    "print(f'ROC_AUC - Test\\t{xgb_best_roc_auc_test}')\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, xgb_best_preds, average='macro')\n",
    "print(f'Precision\\t{round(precision, 3)}')\n",
    "print(f'Recall\\t\\t{round(recall, 3)}')\n",
    "print(f'F-score\\t\\t{round(fscore, 3)}')\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\nConfusion Matrix\\n' + str(confusion_matrix(y_test, xgb_best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Add model and accuracy dict to list\n",
    "model_performance.append(dict([\n",
    "    ('Model', 'XGBoost'),\n",
    "#     ('Train ROC AUC', xgb_best_roc_auc_train),\n",
    "    ('Test ROC AUC', xgb_best_roc_auc_test),\n",
    "    ('Precision', round(precision, 3)),\n",
    "    ('Recall', round(recall, 3)),\n",
    "    ('F1', round(fscore, 3))\n",
    "     ]))\n",
    "\n",
    "# Add model to list\n",
    "models.append('XGBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Confusion Matrix for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# # Print confusion matrix for XGBoost\n",
    "# xgb_confusion = confusion_matrix(y_test, test_pred_smote)\n",
    "\n",
    "# plt.figure(dpi=125)\n",
    "# sns.heatmap(xgb_confusion, annot=True, fmt='g', square=True, cbar=False,\n",
    "#             xticklabels=['no duplicate', 'is duplicate'],\n",
    "#             yticklabels=['no duplicate', 'is duplicate'])\n",
    "\n",
    "# plt.title('Confusion Matrix - Test Dataset\\nXGBoost', pad=20)\n",
    "# plt.xlabel('Predicted\\n', labelpad=20)\n",
    "# plt.ylabel('Actual\\n', labelpad=20);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('metis': conda)",
   "language": "python",
   "name": "python37464bitmetiscondab8a2cd9d238449bd838e7f95913d7792"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
